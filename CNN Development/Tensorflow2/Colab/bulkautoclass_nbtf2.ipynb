{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bulkautoclass_nbtf2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8dFFUFccL2l",
        "colab_type": "text"
      },
      "source": [
        "# PARAMETERS\n",
        "\n",
        "###Update: \n",
        "\n",
        "**True** if you want to update all classifications \n",
        "\n",
        "**False** if you only want to add new classifications"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYo_il1UcArY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "update = True #@param {type:\"boolean\"}\n",
        "fresh = False #@param {type:\"boolean\"}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKTVhFk2pHHd",
        "colab_type": "text"
      },
      "source": [
        "# Installing GDAL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIvWm5RaqFfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!apt-get update\n",
        "!apt-get install libgdal-dev -y\n",
        "!apt-get install python-gdal -y\n",
        "!apt-get install python-numpy python-scipy -y\n",
        "!pip install rasterio\n",
        "!pip install fiona\n",
        "!pip install geopandas\n",
        "import gdal "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWvA4d_DN7kA",
        "colab_type": "text"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnGJOnbSH2A3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "d0b71563-9a74-441b-f09d-15287378b232"
      },
      "source": [
        "from tqdm.autonotebook import tqdm\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import rasterio\n",
        "from descartes import PolygonPatch\n",
        "from rasterio.plot import show\n",
        "import matplotlib as mpl\n",
        "import geopandas\n",
        "import fiona\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TF version: 2.2.0\n",
            "WARNING:tensorflow:From <ipython-input-3-c11d21c3eb78>:17: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n",
            "GPU is available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CilkCxcY_3cQ",
        "colab_type": "text"
      },
      "source": [
        "# Loading Data from Drive\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPUfum5_x1Yk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "04ae6085-9b41-4259-af53-4270cc1c0a54"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJx1spq-k1xf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "690067e4-37ed-47f0-c610-ab80a07c8ce7"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "!cp \"/content/drive/Shared drives/SIO and E4E Mangroves /Data/Machine Learning/Models/mvnmv4_merced_bright.zip\" .\n",
        "!unzip mvnmv4_merced_bright.zip -A\n",
        "\n",
        "#Set model location\n",
        "model = \"/content/mvnmv4_merced/\"\n",
        "model = load_model(model)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  mvnmv4_merced_bright.zip\n",
            "caution: filename not matched:  -A\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj2L3xZESk8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def retile(full_path):\n",
        "    name = os.path.basename(full_path)\n",
        "    file_string = \"\\\"\" + full_path + \"\\\"\"\n",
        "    name_string = \"\\\"\" + os.path.basename(full_path) + \"\\\"\"\n",
        "\n",
        "    print(\"Downloading {}\".format(name))\n",
        "    !cp {file_string} .\n",
        "\n",
        "    !mkdir /content/images\n",
        "    !mkdir /content/images/images\n",
        "\n",
        "    print(\"Retiling {}\".format(name))\n",
        "    call = \"gdal_retile.py -ps 256 256 -targetDir /content/images/images/ /content/\" + name\n",
        "    !{call}\n",
        "\n",
        "    !rm {name}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yznDK60cljGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Since the original model outputs the values from the last dense layer (no final activation), we need to definte the sigmoid function for predicted class conditional probabilities\n",
        "def sigmoid(x):\n",
        "    return 1/(1 + np.exp(-x)) "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEWURwAfsLuc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classify_tiles(image_directory):\n",
        "    print(\"Classifying tiles\")\n",
        "    #Read images using keras and split into batches\n",
        "    image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "    data_gen = image_generator.flow_from_directory(directory=image_directory,\n",
        "                                                        batch_size=32,\n",
        "                                                        shuffle=False,\n",
        "                                                        target_size=(256, 256))\n",
        "    #Set up dataframe that will hold classifications\n",
        "    column_names = [\"prediction\",\"p_0\",\"p_1\",\"filename\"]\n",
        "    result_df = pd.DataFrame(columns=column_names)\n",
        "\n",
        "    #predict probabilities from model for the batches\n",
        "    predictions = model.predict(data_gen)\n",
        "\n",
        "    #associate filenames and classification for each prediction\n",
        "    for i,prediction in tqdm(enumerate(predictions)):\n",
        "        result_df.loc[i,\"filename\"] = data_gen.filenames[i]\n",
        "\n",
        "        #calculating predictions \n",
        "        result_df.loc[i,\"p_0\"] = sigmoid(prediction[0])\n",
        "        result_df.loc[i,\"p_1\"] = sigmoid(prediction[1])\n",
        "        \n",
        "        #getting final class prediction\n",
        "        result_df.loc[i,\"prediction\"] = np.argmax(prediction)\n",
        "    \n",
        "    return result_df"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQ_oo84eseR7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_probtiles(result_df):\n",
        "    print(\"Generating tiles for probability plot\")\n",
        "    for index, sample in tqdm(result_df.iterrows()):\n",
        "        #loading original image\n",
        "        original = os.path.abspath(os.path.join(\"images\", sample[\"filename\"]))\n",
        "        img = rasterio.open(original)\n",
        "\n",
        "        #creating new raster mask with pixel values of conditional probability\n",
        "        mask = sample[\"p_0\"] * np.ones(shape=(img.width, img.height))\n",
        "\n",
        "        #saving file output to new file\n",
        "        filename = \"prob_\" + os.path.basename(sample[\"filename\"])\n",
        "        output = os.path.abspath(os.path.join(\"images\", os.path.dirname(sample[\"filename\"]), filename))\n",
        "        #creates new file with projection of past image\n",
        "        with rasterio.open(output,'w',driver='GTiff',height=img.height,width=img.width,count=1,dtype=mask.dtype,crs='+proj=latlong',transform=img.transform,) as dst:dst.write(mask, 1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvJwFEeSsrFy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def move_tiles(result_df):\n",
        "    print(\"Moving M/NM Tiles into folders\")\n",
        "    dest_folders = []\n",
        "    #Organize tiles into folders\n",
        "    for index, row in result_df.iterrows():\n",
        "        cur_file = \"/content/images/\" + row['filename']\n",
        "        cur_file = cur_file.replace(\"jpg\",\"tif\",2)\n",
        "        classification = row['prediction'] \n",
        "\n",
        "        #set destination folder, and creates the folder if it doesn't exist\n",
        "        dest_folder = os.path.join(os.path.abspath(image_directory),str(classification))\n",
        "        dest_folders.append(dest_folder)\n",
        "        if os.path.exists(dest_folder) == False:\n",
        "            os.mkdir(dest_folder)\n",
        "        dest = os.path.join(dest_folder,os.path.basename(cur_file))\n",
        "\n",
        "        #moves file\n",
        "        src = cur_file\n",
        "        os.rename(src, dest)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9iRg8FRlfEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fix_shp(filename):\n",
        "    shp = geopandas.read_file(filename)\n",
        "    for index, feature in tqdm(shp.iterrows()):\n",
        "        if feature[\"DN\"] == 0:\n",
        "            shp.drop(index, inplace=True)\n",
        "    shp.to_file(filename)\n",
        "    return shp"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUzAtpN-fMv6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_files(full_path):\n",
        "    #remove any already existing files in the path\n",
        "\n",
        "    file = os.path.basename(full_path)\n",
        "    folder = os.path.dirname(full_path)\n",
        "    name = os.path.splitext(file)[0]\n",
        "    dest_folder = os.path.join(folder,name+'_classifications/')\n",
        "\n",
        "    mtif_name = 'm_' + name + '.tif'\n",
        "    mshp_name = 'm_' + name + '.shp'\n",
        "\n",
        "    nmtif_name = 'nm_' + name + '.tif'\n",
        "    nmshp_name = 'nm_' + name + '.shp'\n",
        "\n",
        "    ptif_name =  'prob_' + name + '.tif'\n",
        "    #plot_name =  'plot_' + name + '.png'\n",
        "\n",
        "    !mkdir {\"\\\"\" + dest_folder + \"\\\"\"}\n",
        "\n",
        "\n",
        "    print(\"Creating Orthomosaics\")\n",
        "    #recombines classified tiles for each class\n",
        "    !gdal_merge.py -o /content/{nmtif_name} /content/images/1/*\n",
        "    !rm /content/images/1/*.tif\n",
        "    !gdal_polygonize.py /content/{nmtif_name} -f \"ESRI Shapefile\" -b 4 {nmshp_name}\n",
        "\n",
        "    nmtif_name = 'nm_' + name + '.tif'\n",
        "    nmshp_name = 'nm_' + name + '.shp'\n",
        "    nmshx_name = 'nm_' + name + '.shx'\n",
        "    nmdbf_name = 'nm_' + name + '.dbf'\n",
        "    nmprj_name = 'nm_' + name + '.prj'\n",
        "    nmcpg_name = 'nm_' + name + '.cpg'\n",
        "\n",
        "    nmtif_dest = os.path.join(dest_folder, nmtif_name)\n",
        "    nmshp_dest = os.path.join(dest_folder, nmshp_name)\n",
        "    nmshx_dest = os.path.join(dest_folder, nmshx_name)\n",
        "    nmdbf_dest = os.path.join(dest_folder, nmdbf_name)\n",
        "    nmprj_dest = os.path.join(dest_folder, nmprj_name)\n",
        "    nmcpg_dest = os.path.join(dest_folder, nmcpg_name)\n",
        "\n",
        "    print(\"Uploading Non-Mangrove Files\")\n",
        "\n",
        "    !cp {\"\\\"\" + nmtif_name + \"\\\"\"} {\"\\\"\" + nmtif_dest + \"\\\"\"}\n",
        "    !cp {\"\\\"\" + nmshp_name + \"\\\"\"} {\"\\\"\" + nmshp_dest + \"\\\"\"}\n",
        "    !cp {\"\\\"\" + nmshx_name + \"\\\"\"} {\"\\\"\" + nmshx_dest + \"\\\"\"}\n",
        "    !cp {\"\\\"\" + nmdbf_name + \"\\\"\"} {\"\\\"\" + nmdbf_dest + \"\\\"\"}\n",
        "    !cp {\"\\\"\" + nmprj_name + \"\\\"\"} {\"\\\"\" + nmprj_dest + \"\\\"\"}\n",
        "    !cp {\"\\\"\" + nmcpg_name + \"\\\"\"} {\"\\\"\" + nmcpg_dest + \"\\\"\"}\n",
        "\n",
        "    !rm {nmtif_name}\n",
        "    !rm {nmshp_name}\n",
        "    !rm {nmshx_name}\n",
        "    !rm {nmdbf_name}\n",
        "    !rm {nmprj_name}\n",
        "    !rm {nmcpg_name}\n",
        "\n",
        "\n",
        "    !gdal_merge.py -o /content/{mtif_name} /content/images/0/*\n",
        "    !rm /content/images/0/*.tif\n",
        "    !gdal_polygonize.py /content/{mtif_name} -f \"ESRI Shapefile\" -b 4 {mshp_name}\n",
        "    shp = fix_shp(mshp_name)\n",
        "\n",
        "    mtif_name = 'm_' + name + '.tif'\n",
        "    mshp_name = 'm_' + name + '.shp'\n",
        "    mshx_name = 'm_' + name + '.shx'\n",
        "    mdbf_name = 'm_' + name + '.dbf'\n",
        "    mprj_name = 'm_' + name + '.prj'\n",
        "    mcpg_name = 'm_' + name + '.cpg'\n",
        "\n",
        "    mtif_dest = os.path.join(dest_folder, mtif_name)\n",
        "    mshp_dest = os.path.join(dest_folder, mshp_name)\n",
        "    mshx_dest = os.path.join(dest_folder, mshx_name)\n",
        "    mdbf_dest = os.path.join(dest_folder, mdbf_name)\n",
        "    mprj_dest = os.path.join(dest_folder, mprj_name)\n",
        "    mcpg_dest = os.path.join(dest_folder, mcpg_name)\n",
        "\n",
        "    print(\"Uploading Mangrove Files\")\n",
        "\n",
        "    !cp {\"\\\"\" + mtif_name + \"\\\"\"} {\"\\\"\" + mtif_dest + \"\\\"\"}\n",
        "    !cp {\"\\\"\" + mshp_name + \"\\\"\"} {\"\\\"\" + mshp_dest + \"\\\"\"}\n",
        "    !cp {\"\\\"\" + mshx_name + \"\\\"\"} {\"\\\"\" + mshx_dest + \"\\\"\"}\n",
        "    !cp {\"\\\"\" + mdbf_name + \"\\\"\"} {\"\\\"\" + mdbf_dest + \"\\\"\"}\n",
        "    !cp {\"\\\"\" + mprj_name + \"\\\"\"} {\"\\\"\" + mprj_dest + \"\\\"\"}\n",
        "    !cp {\"\\\"\" + mcpg_name + \"\\\"\"} {\"\\\"\" + mcpg_dest + \"\\\"\"}\n",
        "\n",
        "    !rm {mtif_name}\n",
        "    !rm {mshp_name}\n",
        "    !rm {mshx_name}\n",
        "    !rm {mdbf_name}\n",
        "    !rm {mprj_name}\n",
        "    !rm {mcpg_name}\n",
        "\n",
        "    #probability tiles remain unmoved, so just get all the leftover tiles\n",
        "    !gdal_merge.py -o /content/{ptif_name} /content/images/images/*\n",
        "    !rm -rf /content/images/\n",
        "\n",
        "\n",
        "    ptif_name =  'prob_' + name + '.tif'\n",
        "    plot_name =  'plot_' + name + '.png'\n",
        "\n",
        "    ptif_dest = os.path.join(dest_folder, ptif_name)\n",
        "\n",
        "    print(\"Uploading Other Files\")\n",
        "\n",
        "    !cp {\"\\\"\" + ptif_name + \"\\\"\"} {\"\\\"\" + ptif_dest + \"\\\"\"}\n",
        "\n",
        "    !rm {ptif_name}\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPc3zoSTf2I1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run(full_path,image_directory):\n",
        "    !rm *.tif\n",
        "    !rm *.png\n",
        "    !rm *.cpg\n",
        "    !rm *.dbf\n",
        "    !rm *.prj\n",
        "    !rm *.shp\n",
        "    !rm *.shx\n",
        "\n",
        "    !rm -rf images\n",
        "    retile(full_path)\n",
        "    result_df = classify_tiles(image_directory)\n",
        "    generate_probtiles(result_df)\n",
        "    move_tiles(result_df)\n",
        "    del result_df\n",
        "    create_files(full_path)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10BNEq8EMv7h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stats_pkl = \"/content/drive/Shared drives/SIO and E4E Mangroves /Data/Classification_statistics.pkl\"\n",
        "stats_location = \"/content/drive/Shared drives/SIO and E4E Mangroves /Data/Classification_statistics.xlsx\"\n",
        "\n",
        "class_stats = pd.read_pickle(stats_pkl)\n",
        "class_stats = class_stats.iloc[:-11]\n",
        "\n",
        "class_stats.to_excel(stats_location)\n",
        "pd.to_pickle(class_stats, stats_pkl)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEXol4SOQULe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "f36270b0-1724-41ed-c490-b3d250733c13"
      },
      "source": [
        "columns = [\"filename\",\"filesize (GB)\",\"last_updated\",\"full_path\"]\n",
        "stats_pkl = \"/content/drive/Shared drives/SIO and E4E Mangroves /Data/Classification_statistics.pkl\"\n",
        "\n",
        "if fresh:\n",
        "    class_stats = pd.DataFrame(columns=columns)\n",
        "else:\n",
        "    class_stats = pd.read_pickle(stats_pkl)\n",
        "\n",
        "file_list = []\n",
        "i = 0\n",
        "for root, dirs, files in os.walk(\"/content/drive/Shared drives/SIO and E4E Mangroves /Data/Orthomosaics/\"):\n",
        "    for file in files:\n",
        "        if not((\"dem\" in file) or (\"DEM\" in file)) and not(file.startswith(\"m_\")) and not(file.startswith(\"nm_\")) and not(file.startswith(\"plot_\")) and  (file.endswith(\".tif\")):\n",
        "            if file not in class_stats[\"filename\"].to_list():\n",
        "                full_path = os.path.join(root,file)\n",
        "                file_size = os.path.getsize(full_path)/(1024*1024*1024)\n",
        "                df = pd.DataFrame({\"filename\":file,\"full_path\":full_path,\"filesize (GB)\":file_size}, index=[i] ,columns=columns)\n",
        "                class_stats = class_stats.append(df)\n",
        "            i += 1\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "stats_location = \"/content/drive/Shared drives/SIO and E4E Mangroves /Data/Classification_statistics.xlsx\"\n",
        "\n",
        "for index, row in class_stats.iterrows():\n",
        "    image_directory = \"/content/images\"\n",
        "    full_path = row[\"full_path\"]\n",
        "\n",
        "    if update: \n",
        "        if row.isnull().values.any():\n",
        "            run(full_path,image_directory)\n",
        "            class_stats.loc[index, \"last_updated\"] = datetime.now()\n",
        "            class_stats.to_excel(stats_location)\n",
        "            pd.to_pickle(class_stats, stats_pkl)\n",
        "        else:\n",
        "            continue\n",
        "    else: \n",
        "        run(full_path,image_directory)\n",
        "        class_stats.loc[index, \"last_updated\"] = datetime.now()\n",
        "        class_stats.to_excel(stats_location)\n",
        "        pd.to_pickle(class_stats, stats_pkl)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove '*.png': No such file or directory\n",
            "rm: cannot remove '*.cpg': No such file or directory\n",
            "rm: cannot remove '*.dbf': No such file or directory\n",
            "rm: cannot remove '*.prj': No such file or directory\n",
            "rm: cannot remove '*.shp': No such file or directory\n",
            "rm: cannot remove '*.shx': No such file or directory\n",
            "Downloading psc_2018-05_site10_120m_RGB.tif\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}